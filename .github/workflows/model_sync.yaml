name: Sync Ollama Model to GHCR
on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Nome do modelo (ex: deepseek-r1)'
        required: true
      model_tag:
        description: 'Tag do modelo (ex: 7b, 671b)'
        required: true
      force_resync:
        description: 'ForÃ§ar ressincronizaÃ§Ã£o mesmo se jÃ¡ existir'
        required: false
        type: boolean
        default: false
jobs:
  sync-model:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Set Variables
        id: vars
        run: |
          MODEL_NAME="${{ github.event.inputs.model_name }}"
          MODEL_TAG="${{ github.event.inputs.model_tag }}"
          FORCE="${{ github.event.inputs.force_resync }}"
          MODEL_FULL="${MODEL_NAME}:${MODEL_TAG}"
          TARGET="ghcr.io/${{ github.repository_owner }}/${MODEL_NAME}:${MODEL_TAG}"
          echo "MODEL_NAME=${MODEL_NAME}" >> $GITHUB_ENV
          echo "MODEL_TAG=${MODEL_TAG}" >> $GITHUB_ENV
          echo "MODEL_FULL=${MODEL_FULL}" >> $GITHUB_ENV
          echo "FORCE=${FORCE}" >> $GITHUB_ENV
          echo "TARGET=${TARGET}" >> $GITHUB_ENV
      
      - name: Login no GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}
      
      - name: Check if Image Exists
        id: check
        continue-on-error: true
        run: |
          if [[ "${FORCE}" != "true" ]]; then
            if docker manifest inspect "${TARGET}" >/dev/null 2>&1; then
              echo "EXISTS=true" >> $GITHUB_ENV
              echo "âœ… JÃ¡ existe: ${TARGET}"
            else
              echo "EXISTS=false" >> $GITHUB_ENV
            fi
          else
            echo "EXISTS=false" >> $GITHUB_ENV
            echo "ðŸ”„ ForÃ§ando ressincronizaÃ§Ã£o"
          fi
      
      - name: Construir Imagem Ollama com Formato Correto
        if: env.EXISTS == 'false'
        run: |
          # Criar diretÃ³rio temporÃ¡rio
          TEMP_DIR=$(mktemp -d)
          
          echo "ðŸ”§ Criando Dockerfile compatÃ­vel com Ollama para o modelo ${MODEL_FULL}"
          
          # Criar Dockerfile com formato correto para Ollama
          cat > ${TEMP_DIR}/Dockerfile << 'EOF'
          # EstÃ¡gio 1: Baixar modelo com Ollama
          FROM ollama/ollama:latest AS builder
          ARG MODEL_NAME
          
          # Inicializar Ollama e baixar o modelo
          RUN echo "ðŸ“¥ Iniciando Ollama e baixando modelo: ${MODEL_NAME}" && \
              ollama serve & \
              sleep 5 && \
              ollama pull ${MODEL_NAME} && \
              sleep 2
          
          # Localizar os arquivos do modelo
          RUN mkdir -p /tmp/ollama_model && \
              find /root/.ollama -name "*.bin" -o -name "*.json" -o -name "*.gguf" | \
              xargs -I{} cp -v {} /tmp/ollama_model/ && \
              find /root/.ollama -name "manifest.json" | \
              xargs -I{} cp -v {} /tmp/ollama_model/
          
          # EstÃ¡gio 2: Imagem final com estrutura Ollama-compatÃ­vel
          FROM scratch
          
          # Copiar arquivos do modelo
          COPY --from=builder /tmp/ollama_model /
          
          # Adicionar metadados especÃ­ficos do Ollama
          LABEL org.opencontainers.image.title="ollama-model"
          LABEL org.opencontainers.image.description="Ollama model compatible image"
          
          CMD [""]
          EOF
          
          echo "ðŸ—ï¸ Construindo imagem Docker..."
          cd ${TEMP_DIR}
          docker build --build-arg MODEL_NAME=${MODEL_FULL} -t ${TARGET} .
          
          echo "ðŸ“¤ Enviando imagem para GHCR..."
          docker push ${TARGET}
      
      - name: Resultado
        run: |
          if [[ "${EXISTS}" == "true" ]]; then
            echo "â„¹ï¸ Nenhuma aÃ§Ã£o: imagem jÃ¡ existia em GHCR."
          else
            echo "âœ… Modelo publicado: ${TARGET}"
            echo "Para usar localmente:"
            echo "1. Crie um arquivo Modelfile:"
            echo "FROM ${TARGET}"
            echo "2. Execute: ollama create modelo-local -f ./Modelfile"
            echo "3. Use: ollama run modelo-local"
          fi
