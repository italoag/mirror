name: Sync Ollama Model to GHCR
on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Nome do modelo (ex: deepseek-r1)'
        required: true
      model_tag:
        description: 'Tag do modelo (ex: 7b, 671b)'
        required: true
      force_resync:
        description: 'Forçar ressincronização mesmo se já existir'
        required: false
        type: boolean
        default: false
jobs:
  sync-model:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Set Variables
        id: vars
        run: |
          MODEL_NAME="${{ github.event.inputs.model_name }}"
          MODEL_TAG="${{ github.event.inputs.model_tag }}"
          FORCE="${{ github.event.inputs.force_resync }}"
          MODEL_FULL="${MODEL_NAME}:${MODEL_TAG}"
          TARGET="ghcr.io/${{ github.repository_owner }}/public/${MODEL_NAME}:${MODEL_TAG}"
          echo "MODEL_NAME=${MODEL_NAME}" >> $GITHUB_ENV
          echo "MODEL_TAG=${MODEL_TAG}" >> $GITHUB_ENV
          echo "MODEL_FULL=${MODEL_FULL}" >> $GITHUB_ENV
          echo "FORCE=${FORCE}" >> $GITHUB_ENV
          echo "TARGET=${TARGET}" >> $GITHUB_ENV
      
      - name: Login no GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}
      
      - name: Check if Image Exists
        id: check
        continue-on-error: true
        run: |
          if [[ "${FORCE}" != "true" ]]; then
            if docker manifest inspect "${TARGET}" >/dev/null 2>&1; then
              echo "EXISTS=true" >> $GITHUB_ENV
              echo "✅ Já existe: ${TARGET}"
            else
              echo "EXISTS=false" >> $GITHUB_ENV
            fi
          else
            echo "EXISTS=false" >> $GITHUB_ENV
            echo "🔄 Forçando ressincronização"
          fi
      
      - name: Instalar Ollama
        if: env.EXISTS == 'false'
        run: |
          curl -fsSL https://ollama.com/install.sh | sh
          ollama --version
      
      - name: Baixar Modelo Ollama e Criar Imagem Docker
        if: env.EXISTS == 'false'
        run: |
          echo "📥 Pull do modelo ${MODEL_FULL} via Ollama"
          # Iniciar o serviço Ollama em background
          ollama serve &
          
          # Aguardar inicialização do serviço
          sleep 5
          
          # Baixar o modelo
          ollama pull ${MODEL_FULL}
          
          # Encontrar onde o Ollama armazena os modelos
          OLLAMA_MODELS_DIR=~/.ollama/models
          
          # Encontrar o diretório específico do modelo (pode variar dependendo da versão do Ollama)
          MODEL_DIR=$(find ${OLLAMA_MODELS_DIR} -type d -name "${MODEL_NAME}*${MODEL_TAG}*" | head -n 1)
          
          if [ -z "$MODEL_DIR" ]; then
            echo "❌ Não foi possível encontrar o diretório do modelo"
            ls -la ${OLLAMA_MODELS_DIR}
            exit 1
          fi
          
          echo "📦 Modelo encontrado em: ${MODEL_DIR}"
          
          # Criar diretório temporário para o modelo
          TEMP_DIR=$(mktemp -d)
          cp -r ${MODEL_DIR}/* ${TEMP_DIR}/
          
          # Criar Dockerfile
          cat > ${TEMP_DIR}/Dockerfile << EOF
          FROM scratch
          COPY . /
          LABEL org.opencontainers.image.description="Ollama model ${MODEL_FULL}"
          CMD [""]
          EOF
          
          # Construir e enviar imagem
          cd ${TEMP_DIR}
          docker build -t ${TARGET} .
          docker push ${TARGET}
      
      - name: Resultado
        run: |
          if [[ "${EXISTS}" == "true" ]]; then
            echo "ℹ️ Nenhuma ação: imagem já existia em GHCR."
          else
            echo "✅ Modelo publicado: ${TARGET}"
            echo "   Para usar: ollama pull ${TARGET}"
          fi
