name: Sync Ollama Model to GHCR
on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Nome do modelo (ex: deepseek-r1)'
        required: true
      model_tag:
        description: 'Tag do modelo (ex: 7b, 671b)'
        required: true
      force_resync:
        description: 'ForÃ§ar ressincronizaÃ§Ã£o mesmo se jÃ¡ existir'
        required: false
        type: boolean
        default: false
jobs:
  sync-model:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Set Variables
        id: vars
        run: |
          MODEL_NAME="${{ github.event.inputs.model_name }}"
          MODEL_TAG="${{ github.event.inputs.model_tag }}"
          FORCE="${{ github.event.inputs.force_resync }}"
          MODEL_FULL="${MODEL_NAME}:${MODEL_TAG}"
          TARGET="ghcr.io/${{ github.repository_owner }}/${MODEL_NAME}:${MODEL_TAG}"
          echo "MODEL_NAME=${MODEL_NAME}" >> $GITHUB_ENV
          echo "MODEL_TAG=${MODEL_TAG}" >> $GITHUB_ENV
          echo "MODEL_FULL=${MODEL_FULL}" >> $GITHUB_ENV
          echo "FORCE=${FORCE}" >> $GITHUB_ENV
          echo "TARGET=${TARGET}" >> $GITHUB_ENV
      
      - name: Login no GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}
      
      - name: Check if Image Exists
        id: check
        continue-on-error: true
        run: |
          IMAGE_EXISTS="false"
          if [[ "${FORCE}" != "true" ]]; then
            if docker manifest inspect "${TARGET}" >/dev/null 2>&1; then
              IMAGE_EXISTS="true"
              echo "âœ… JÃ¡ existe: ${TARGET}"
            fi
          fi
          echo "EXISTS=${IMAGE_EXISTS}" >> $GITHUB_ENV
      
      - name: Instalar DependÃªncias
        if: env.EXISTS == 'false'
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl
          
          # Instalar Ollama
          curl -fsSL https://ollama.com/install.sh | sh
      
      - name: Exportar e Sincronizar Modelo
        if: env.EXISTS == 'false'
        run: |
          echo "ðŸ”„ Exportando modelo ${MODEL_FULL}..."
          
          # Definir variÃ¡veis
          OLLAMA_HOME="$HOME/.ollama"
          BLOBS_PATH="$OLLAMA_HOME/models/blobs"
          MANIFESTS_PATH="$OLLAMA_HOME/models/manifests"
          EXPORT_DIR="/tmp/ollama-export-${MODEL_NAME}-${MODEL_TAG}"
          REGISTRY="registry.ollama.ai"
          LIBRARY="library"
          
          # Criar diretÃ³rio de exportaÃ§Ã£o
          mkdir -p "${EXPORT_DIR}"
          
          # Iniciar serviÃ§o Ollama
          ollama serve &
          sleep 5
          
          # Baixar o modelo
          echo "ðŸ“¥ Baixando modelo ${MODEL_FULL}..."
          ollama pull ${MODEL_FULL}
          sleep 2
          
          # Verificar se o manifesto existe
          MANIFEST_FILE="${MANIFESTS_PATH}/${REGISTRY}/${LIBRARY}/${MODEL_NAME}/${MODEL_TAG}"
          if [ ! -f "${MANIFEST_FILE}" ]; then
            echo "âŒ Manifesto nÃ£o encontrado: ${MANIFEST_FILE}"
            
            # Listar diretÃ³rios para depuraÃ§Ã£o
            echo "ðŸ“‚ Estrutura de diretÃ³rios:"
            find "${OLLAMA_HOME}" -type d | sort
            
            echo "ðŸ“„ Manifestos encontrados:"
            find "${MANIFESTS_PATH}" -type f | sort
            
            exit 1
          fi
          
          echo "âœ… Manifesto encontrado: ${MANIFEST_FILE}"
          
          # Criar Modelfile inicial
          echo "FROM ./model.bin" > "${EXPORT_DIR}/Modelfile"
          
          # Processar as camadas do manifesto
          echo "ðŸ” Processando camadas do manifesto..."
          jq -r '.layers[].digest' "${MANIFEST_FILE}" | while read layer; do
            BLOB_FILE="${BLOBS_PATH}/${layer//:/-}"
            BLOB_TYPE=$(jq -r --arg layer "$layer" '.layers[] | select(.digest == $layer) | .mediaType' "${MANIFEST_FILE}" | sed 's|.*\.ollama\.image\.\(.*\)|\1|')
            
            echo "Processando: ${layer} (tipo: ${BLOB_TYPE})"
            
            case "${BLOB_TYPE}" in
              model)
                echo "ðŸ“¦ Copiando arquivo do modelo..."
                cp "${BLOB_FILE}" "${EXPORT_DIR}/model.bin"
                ;;
              params)
                echo "âš™ï¸ Processando parÃ¢metros..."
                PARAMS_JSON=$(cat "${BLOB_FILE}")
                echo "${PARAMS_JSON}" | jq -r 'keys[] as $key | .[$key][] | "PARAMETER \($key) \"\(.)\""' >> "${EXPORT_DIR}/Modelfile"
                ;;
              *)
                TYPE_NAME=$(echo "${BLOB_TYPE}" | tr '[:lower:]' '[:upper:]')
                FILE_CONTENT=$(cat "${BLOB_FILE}")
                echo "${TYPE_NAME} \"\"\"${FILE_CONTENT}\"\"\"" >> "${EXPORT_DIR}/Modelfile"
                ;;
            esac
          done
          
          # Verificar os arquivos exportados
          echo "ðŸ“‹ Arquivos exportados:"
          ls -lah "${EXPORT_DIR}"
          
          # Verificar tamanho do arquivo de modelo
          if [ -f "${EXPORT_DIR}/model.bin" ]; then
            MODEL_SIZE=$(du -sh "${EXPORT_DIR}/model.bin" | cut -f1)
            echo "ðŸ“Š Tamanho do arquivo de modelo: ${MODEL_SIZE}"
          else
            echo "âŒ Arquivo de modelo nÃ£o encontrado!"
            exit 1
          fi
          
          # Criar Dockerfile
          cat > "${EXPORT_DIR}/Dockerfile" << EOF
          FROM scratch
          COPY . /
          LABEL org.opencontainers.image.title="${MODEL_FULL}"
          LABEL org.opencontainers.image.description="Ollama model ${MODEL_FULL} synced via GitHub Actions"
          LABEL org.opencontainers.image.visibility="public"
          CMD [""]
          EOF
          
          # Construir imagem Docker
          echo "ðŸ—ï¸ Construindo imagem Docker..."
          cd "${EXPORT_DIR}"
          docker build -t "${TARGET}" .
          
          # Verificar tamanho da imagem
          IMAGE_SIZE=$(docker image ls "${TARGET}" --format "{{.Size}}")
          echo "ðŸ“Š Tamanho da imagem Docker: ${IMAGE_SIZE}"
          
          # Verificar se a imagem tem tamanho razoÃ¡vel
          if [[ "${IMAGE_SIZE}" == *"kB"* || "${IMAGE_SIZE}" == *"KB"* ]]; then
            KB_SIZE=$(echo "${IMAGE_SIZE}" | sed 's/[^0-9]//g')
            if [[ $KB_SIZE -lt 1000 ]]; then
              echo "âŒ A imagem Ã© muito pequena (${IMAGE_SIZE})!"
              exit 1
            fi
          fi
          
          # Definir visibilidade pÃºblica da imagem
          echo "ðŸ”“ Configurando visibilidade pÃºblica..."
          
          # Enviar imagem para GHCR
          echo "ðŸ“¤ Enviando imagem para GHCR..."
          docker push "${TARGET}"
          
          # Tornar o pacote pÃºblico via API
          REPO_NAME="${{ github.repository_owner }}/${MODEL_NAME}"
          echo "ðŸ”“ Tornando o pacote pÃºblico via API GitHub..."
          
          curl -X PATCH \
            -H "Authorization: token ${{ secrets.GHCR_PAT }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/orgs/${{ github.repository_owner }}/packages/container/${MODEL_NAME}/versions" \
            -d '{"visibility":"public"}'
      
      - name: Resultado
        run: |
          if [[ "${EXISTS}" == "true" && "${FORCE}" != "true" ]]; then
            echo "â„¹ï¸ Nenhuma aÃ§Ã£o: imagem jÃ¡ existia em GHCR."
          else
            echo "âœ… Modelo publicado: ${TARGET}"
            echo ""
            echo "Para usar localmente:"
            echo "1. Crie um arquivo Modelfile com o conteÃºdo:"
            echo "FROM ${TARGET}"
            echo ""
            echo "2. Execute: ollama create modelo-local -f ./Modelfile"
            echo "3. Use: ollama run modelo-local"
          fi
