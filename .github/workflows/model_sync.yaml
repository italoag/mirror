name: Sync Ollama Model to GHCR (API Direct)
on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Nome do modelo (ex: deepseek-r1)'
        required: true
      model_tag:
        description: 'Tag do modelo (ex: 7b, 671b)'
        required: true
      force_resync:
        description: 'ForÃ§ar ressincronizaÃ§Ã£o mesmo se jÃ¡ existir'
        required: false
        type: boolean
        default: false
jobs:
  sync-model:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Set Variables
        id: vars
        run: |
          MODEL_NAME="${{ github.event.inputs.model_name }}"
          MODEL_TAG="${{ github.event.inputs.model_tag }}"
          FORCE="${{ github.event.inputs.force_resync }}"
          MODEL_FULL="${MODEL_NAME}:${MODEL_TAG}"
          TARGET="ghcr.io/${{ github.repository_owner }}/${MODEL_NAME}:${MODEL_TAG}"
          echo "MODEL_NAME=${MODEL_NAME}" >> $GITHUB_ENV
          echo "MODEL_TAG=${MODEL_TAG}" >> $GITHUB_ENV
          echo "MODEL_FULL=${MODEL_FULL}" >> $GITHUB_ENV
          echo "FORCE=${FORCE}" >> $GITHUB_ENV
          echo "TARGET=${TARGET}" >> $GITHUB_ENV
      
      - name: Instalar DependÃªncias
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl
      
      - name: Login no GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}
      
      - name: Check if Image Exists
        id: check
        continue-on-error: true
        run: |
          IMAGE_EXISTS="false"
          if [[ "${FORCE}" != "true" ]]; then
            if docker manifest inspect "${TARGET}" >/dev/null 2>&1; then
              IMAGE_EXISTS="true"
              echo "âœ… JÃ¡ existe: ${TARGET}"
            fi
          fi
          echo "EXISTS=${IMAGE_EXISTS}" >> $GITHUB_ENV
      
      - name: Download direto da API do Ollama Registry
        if: env.EXISTS == 'false'
        run: |
          echo "ðŸ”„ Sincronizando modelo ${MODEL_FULL} diretamente da API..."
          
          # Preparar diretÃ³rios
          mkdir -p /tmp/ollama-api/model-files
          cd /tmp/ollama-api
          
          # Obter o manifesto do modelo
          REGISTRY_URL="https://registry.ollama.ai/v2/library/${MODEL_NAME}/manifests/${MODEL_TAG}"
          echo "ðŸ“¥ Baixando manifesto de: ${REGISTRY_URL}"
          
          curl -s "${REGISTRY_URL}" > manifest.json
          
          if [ ! -s manifest.json ]; then
            echo "âŒ Falha ao baixar o manifesto!"
            exit 1
          fi
          
          echo "âœ… Manifesto baixado com sucesso"
          cat manifest.json | jq
          
          # Extrair layers do manifesto
          echo "ðŸ” Extraindo informaÃ§Ãµes de layers..."
          jq -r '.layers[].digest' manifest.json > layers.txt
          
          # Baixar cada layer
          mkdir -p model-files
          cat layers.txt | while read layer; do
            layer_file=$(echo $layer | sed 's/sha256://g')
            echo "ðŸ“¥ Baixando layer: ${layer}"
            curl -sL "https://registry.ollama.ai/v2/library/${MODEL_NAME}/blobs/${layer}" > "model-files/${layer_file}"
            
            # Verificar o tipo de layer baseado no manifesto
            layer_type=$(jq -r --arg layer "${layer}" '.layers[] | select(.digest == $layer) | .mediaType' manifest.json | sed 's|.*\.ollama\.image\.\(.*\)|\1|')
            echo "   Tipo: ${layer_type}"
            
            # Se for o arquivo de modelo, renomeie-o
            if [[ "${layer_type}" == "model" ]]; then
              echo "âœ… Encontrado arquivo principal do modelo: ${layer_file}"
              mv "model-files/${layer_file}" "model-files/model.bin"
            fi
          done
          
          # Verificar os arquivos baixados
          echo "ðŸ“‹ Arquivos baixados:"
          ls -lah model-files/
          
          # Verificar tamanho total
          TOTAL_SIZE=$(du -sh model-files/ | cut -f1)
          echo "ðŸ“Š Tamanho total dos arquivos: ${TOTAL_SIZE}"
          
          # Criar Dockerfile
          cat > model-files/Dockerfile << EOF
          FROM scratch
          COPY . /
          LABEL org.opencontainers.image.title="${MODEL_FULL}"
          LABEL org.opencontainers.image.description="Ollama model ${MODEL_FULL} synced via GitHub Actions"
          CMD [""]
          EOF
          
          # Construir imagem Docker
          echo "ðŸ—ï¸ Construindo imagem Docker..."
          cd model-files/
          docker build -t ${TARGET} .
          
          # Verificar tamanho da imagem
          IMAGE_SIZE=$(docker image ls ${TARGET} --format "{{.Size}}")
          echo "ðŸ“Š Tamanho da imagem Docker: ${IMAGE_SIZE}"
          
          if [[ "${IMAGE_SIZE}" == *"kB"* || "${IMAGE_SIZE}" == *"KB"* ]]; then
            KB_SIZE=$(echo "${IMAGE_SIZE}" | sed 's/[^0-9]//g')
            if [[ $KB_SIZE -lt 1000 ]]; then
              echo "âŒ A imagem Ã© muito pequena (${IMAGE_SIZE})!"
              exit 1
            fi
          fi
          
          # Enviar imagem para GHCR
          echo "ðŸ“¤ Enviando imagem para GHCR..."
          docker push ${TARGET}
          
          # Tornar o pacote pÃºblico via GitHub API
          echo "ðŸ”“ Configurando visibilidade pÃºblica do pacote..."
          PACKAGE_NAME=$(echo "${MODEL_NAME}" | tr '[:upper:]' '[:lower:]')
          
          curl -X PATCH \
            -H "Authorization: token ${{ secrets.GHCR_PAT }}" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/user/packages/container/${PACKAGE_NAME}/visibility" \
            -d '{"visibility":"public"}'
      
      - name: Resultado
        run: |
          if [[ "${EXISTS}" == "true" ]]; then
            echo "â„¹ï¸ Nenhuma aÃ§Ã£o: imagem jÃ¡ existia em GHCR."
          else
            echo "âœ… Modelo publicado: ${TARGET}"
            echo ""
            echo "Para usar localmente:"
            echo "ollama pull ${TARGET}"
          fi
