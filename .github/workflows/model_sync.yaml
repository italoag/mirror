name: Sync Ollama Model to GHCR
on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Nome do modelo (ex: deepseek-r1)'
        required: true
      model_tag:
        description: 'Tag do modelo (ex: 7b, 671b)'
        required: true
      force_resync:
        description: 'ForÃ§ar ressincronizaÃ§Ã£o mesmo se jÃ¡ existir'
        required: false
        type: boolean
        default: false
jobs:
  sync-model:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Set Variables
        id: vars
        run: |
          MODEL_NAME="${{ github.event.inputs.model_name }}"
          MODEL_TAG="${{ github.event.inputs.model_tag }}"
          FORCE="${{ github.event.inputs.force_resync }}"
          MODEL_FULL="${MODEL_NAME}:${MODEL_TAG}"
          TARGET="ghcr.io/${{ github.repository_owner }}/${MODEL_NAME}:${MODEL_TAG}"
          echo "MODEL_NAME=${MODEL_NAME}" >> $GITHUB_ENV
          echo "MODEL_TAG=${MODEL_TAG}" >> $GITHUB_ENV
          echo "MODEL_FULL=${MODEL_FULL}" >> $GITHUB_ENV
          echo "FORCE=${FORCE}" >> $GITHUB_ENV
          echo "TARGET=${TARGET}" >> $GITHUB_ENV
      
      - name: Login no GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}
      
      - name: Check if Image Exists
        id: check
        continue-on-error: true
        run: |
          if [[ "${FORCE}" != "true" ]]; then
            if docker manifest inspect "${TARGET}" >/dev/null 2>&1; then
              echo "EXISTS=true" >> $GITHUB_ENV
              echo "âœ… JÃ¡ existe: ${TARGET}"
            else
              echo "EXISTS=false" >> $GITHUB_ENV
            fi
          else
            echo "EXISTS=false" >> $GITHUB_ENV
            echo "ðŸ”„ ForÃ§ando ressincronizaÃ§Ã£o"
          fi
      
      - name: Configurar Ambiente para Ollama
        if: env.EXISTS == 'false'
        run: |
          # Instalar Ollama localmente
          curl -fsSL https://ollama.com/install.sh | sh
          
          # Criar diretÃ³rios de trabalho
          mkdir -p /tmp/ollama-data
          mkdir -p /tmp/model-files
          
          # Inicie o serviÃ§o Ollama
          echo "ðŸš€ Iniciando o serviÃ§o Ollama..."
          ollama serve &
          sleep 5
          
          # Baixar o modelo
          echo "ðŸ“¥ Baixando modelo ${MODEL_FULL}..."
          ollama pull ${MODEL_FULL}
          
          # Encontrar diretÃ³rio onde o Ollama armazena os modelos
          OLLAMA_DIR="$HOME/.ollama"
          echo "ðŸ” Verificando diretÃ³rio do Ollama: ${OLLAMA_DIR}"
          
          # Verificar estrutura de diretÃ³rios
          echo "ðŸ“‚ Estrutura de diretÃ³rios:"
          find ${OLLAMA_DIR} -type d | sort
          
          # Verificar arquivos grandes
          echo "ðŸ“„ Arquivos grandes (>10MB):"
          find ${OLLAMA_DIR} -type f -size +10M | sort
          
          # Copiar arquivos relevantes
          echo "ðŸ“¦ Copiando arquivos..."
          
          # Arquivos binÃ¡rios e de configuraÃ§Ã£o
          for EXT in "bin" "gguf" "json"; do
            find ${OLLAMA_DIR} -name "*.${EXT}" -exec cp -v {} /tmp/model-files/ \;
          done
          
          # Copiar arquivos grandes (modelo principal)
          find ${OLLAMA_DIR} -type f -size +10M -exec cp -v {} /tmp/model-files/ \;
          
          # Verificar conteÃºdo
          echo "ðŸ“‹ Arquivos copiados:"
          ls -lah /tmp/model-files/
          
          # Se nÃ£o encontrar arquivos, tentar diretÃ³rio de blobs
          if [ ! "$(ls -A /tmp/model-files/)" ]; then
            echo "âš ï¸ Nenhum arquivo encontrado. Tentando copiar diretÃ³rios de blobs..."
            BLOBS_DIR=$(find ${OLLAMA_DIR} -path "*/blobs" -type d | head -n 1)
            
            if [ -n "$BLOBS_DIR" ]; then
              echo "Copiando blobs de: ${BLOBS_DIR}"
              cp -rv ${BLOBS_DIR}/* /tmp/model-files/
            fi
            
            # Verificar novamente
            echo "ðŸ“‹ Arquivos apÃ³s tentativa de blobs:"
            ls -lah /tmp/model-files/
          fi
          
          # Segunda alternativa - explorar /usr/local
          if [ ! "$(ls -A /tmp/model-files/)" ]; then
            echo "âš ï¸ Tentando localizar em /usr/local/share/ollama..."
            if [ -d "/usr/local/share/ollama" ]; then
              find /usr/local/share/ollama -type f -size +1M -exec cp -v {} /tmp/model-files/ \;
            fi
            
            echo "ðŸ“‹ Arquivos apÃ³s tentativa alternativa:"
            ls -lah /tmp/model-files/
          fi
          
          # Verificar tamanho total
          TOTAL_SIZE=$(du -sh /tmp/model-files/ | cut -f1)
          echo "ðŸ“Š Tamanho total dos arquivos: ${TOTAL_SIZE}"
          
          if [ ! "$(ls -A /tmp/model-files/)" ]; then
            echo "âŒ NÃ£o foi possÃ­vel encontrar os arquivos do modelo!"
            
            # ExploraÃ§Ã£o mais profunda
            echo "ðŸ”Ž Realizando busca em todo o sistema por arquivos de modelo..."
            sudo find / -name "*.gguf" -o -name "*.bin" -size +100M 2>/dev/null | grep -v "proc\|sys" | head -n 10
            
            exit 1
          fi
          
          # Criar Dockerfile
          echo "ðŸ“ Criando Dockerfile..."
          cat > /tmp/model-files/Dockerfile << EOF
          FROM scratch
          COPY . /
          LABEL org.opencontainers.image.title="${MODEL_FULL}"
          LABEL org.opencontainers.image.description="Ollama model ${MODEL_FULL} synced via GitHub Actions"
          CMD [""]
          EOF
          
          # Construir imagem
          echo "ðŸ—ï¸ Construindo imagem Docker..."
          cd /tmp/model-files/
          docker build -t ${TARGET} .
          
          # Verificar tamanho da imagem
          IMAGE_SIZE=$(docker image ls ${TARGET} --format "{{.Size}}")
          echo "ðŸ“Š Tamanho da imagem: ${IMAGE_SIZE}"
          
          if [[ "${IMAGE_SIZE}" == *"kB"* || "${IMAGE_SIZE}" == *"KB"* ]]; then
            echo "âš ï¸ A imagem parece muito pequena (${IMAGE_SIZE})!"
            if [[ "${IMAGE_SIZE}" == "1.1kB" || "${IMAGE_SIZE}" == "1.1KB" ]]; then
              echo "âŒ A imagem tem exatamente 1.1KB, o que indica que nÃ£o hÃ¡ arquivos de modelo!"
              exit 1
            fi
          fi
          
          # Enviar imagem para GHCR
          echo "ðŸ“¤ Enviando imagem para GHCR..."
          docker push ${TARGET}
      
      - name: Resultado
        run: |
          if [[ "${EXISTS}" == "true" ]]; then
            echo "â„¹ï¸ Nenhuma aÃ§Ã£o: imagem jÃ¡ existia em GHCR."
          else
            echo "âœ… Modelo publicado: ${TARGET}"
            echo ""
            echo "Para usar localmente:"
            echo "1. Crie um arquivo Modelfile com o conteÃºdo:"
            echo "FROM ${TARGET}"
            echo ""
            echo "2. Execute: ollama create modelo-local -f ./Modelfile"
            echo "3. Use: ollama run modelo-local"
          fi
