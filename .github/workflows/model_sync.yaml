name: Sync Ollama Model to GHCR
on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Nome do modelo (ex: deepseek-r1)'
        required: true
      model_tag:
        description: 'Tag do modelo (ex: 7b, 671b)'
        required: true
      force_resync:
        description: 'Forçar ressincronização mesmo se já existir'
        required: false
        type: boolean
        default: false
jobs:
  sync-model:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Set Variables
        id: vars
        run: |
          MODEL_NAME="${{ github.event.inputs.model_name }}"
          MODEL_TAG="${{ github.event.inputs.model_tag }}"
          FORCE="${{ github.event.inputs.force_resync }}"
          MODEL_FULL="${MODEL_NAME}:${MODEL_TAG}"
          TARGET="ghcr.io/${{ github.repository_owner }}/${MODEL_NAME}:${MODEL_TAG}"
          echo "MODEL_NAME=${MODEL_NAME}" >> $GITHUB_ENV
          echo "MODEL_TAG=${MODEL_TAG}" >> $GITHUB_ENV
          echo "MODEL_FULL=${MODEL_FULL}" >> $GITHUB_ENV
          echo "FORCE=${FORCE}" >> $GITHUB_ENV
          echo "TARGET=${TARGET}" >> $GITHUB_ENV
      
      - name: Login no GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}
      
      - name: Check if Image Exists
        id: check
        continue-on-error: true
        run: |
          if [[ "${FORCE}" != "true" ]]; then
            if docker manifest inspect "${TARGET}" >/dev/null 2>&1; then
              echo "EXISTS=true" >> $GITHUB_ENV
              echo "✅ Já existe: ${TARGET}"
            else
              echo "EXISTS=false" >> $GITHUB_ENV
            fi
          else
            echo "EXISTS=false" >> $GITHUB_ENV
            echo "🔄 Forçando ressincronização"
          fi
      
      - name: Download e Sincronização do Modelo
        if: env.EXISTS == 'false'
        run: |
          echo "🔄 Iniciando processo de sincronização para modelo ${MODEL_FULL}"
          
          # Criar diretórios de trabalho
          mkdir -p /tmp/ollama-data
          mkdir -p /tmp/model-files
          
          # Executar container Docker com Ollama e baixar o modelo
          echo "📥 Baixando modelo ${MODEL_FULL}..."
          docker run --name ollama-downloader \
            -v /tmp/ollama-data:/root/.ollama \
            ollama/ollama bash -c "ollama serve & sleep 5 && ollama pull ${MODEL_FULL} && sleep 2"
          
          # Listar estrutura de diretórios para debug
          echo "🔍 Estrutura de diretórios de volume do Ollama:"
          find /tmp/ollama-data -type d | sort
          
          # Explorar e listar todos os arquivos grandes
          echo "🔍 Procurando arquivos de modelo (>= 1MB):"
          find /tmp/ollama-data -type f -size +1M | sort
          
          # Encontrar e copiar arquivos de modelo 
          echo "📦 Copiando arquivos de modelo para diretório temporário..."
          
          # Arquivos binários (*.bin)
          find /tmp/ollama-data -type f -name "*.bin" -exec cp -v {} /tmp/model-files/ \;
          
          # Arquivos GGUF (*.gguf)
          find /tmp/ollama-data -type f -name "*.gguf" -exec cp -v {} /tmp/model-files/ \;
          
          # Arquivos JSON (*.json)
          find /tmp/ollama-data -type f -name "*.json" -exec cp -v {} /tmp/model-files/ \;
          
          # Arquivos de modelo (model.*)
          find /tmp/ollama-data -type f -name "model.*" -exec cp -v {} /tmp/model-files/ \;
          
          # Copiar quaisquer arquivos grandes (maior que 10MB) 
          find /tmp/ollama-data -type f -size +10M -exec cp -v {} /tmp/model-files/ \;
          
          # Verificar se há arquivos copiados
          echo "📋 Verificando arquivos copiados:"
          ls -lah /tmp/model-files/
          
          # Verificar tamanho total
          TOTAL_SIZE=$(du -sh /tmp/model-files/ | cut -f1)
          echo "📊 Tamanho total dos arquivos copiados: ${TOTAL_SIZE}"
          
          if [ ! "$(ls -A /tmp/model-files/)" ]; then
            echo "❌ Nenhum arquivo de modelo encontrado! Explorando mais diretórios..."
            
            # Tentativa adicional: copiar pastas inteiras
            MODEL_BLOBS_DIR=$(find /tmp/ollama-data -path "*/blobs" -type d | head -n 1)
            if [ -n "$MODEL_BLOBS_DIR" ]; then
              echo "📦 Copiando diretório de blobs: ${MODEL_BLOBS_DIR}"
              cp -r ${MODEL_BLOBS_DIR}/* /tmp/model-files/
            fi
            
            # Verificar novamente
            echo "📋 Verificando arquivos após tentativa adicional:"
            ls -lah /tmp/model-files/
            
            TOTAL_SIZE=$(du -sh /tmp/model-files/ | cut -f1)
            echo "📊 Tamanho total dos arquivos copiados: ${TOTAL_SIZE}"
            
            if [ ! "$(ls -A /tmp/model-files/)" ]; then
              echo "❌ Falha ao encontrar arquivos de modelo!"
              exit 1
            fi
          fi
          
          # Criar Dockerfile
          echo "📝 Criando Dockerfile..."
          cat > /tmp/model-files/Dockerfile << EOF
          FROM scratch
          COPY . /
          LABEL org.opencontainers.image.title="${MODEL_FULL}"
          LABEL org.opencontainers.image.description="Ollama model ${MODEL_FULL} synced via GitHub Actions"
          LABEL org.opencontainers.image.source="https://github.com/ollama/ollama"
          CMD [""]
          EOF
          
          # Construir imagem Docker
          echo "🏗️ Construindo imagem Docker..."
          cd /tmp/model-files/
          docker build -t ${TARGET} .
          
          # Verificar tamanho da imagem
          IMAGE_SIZE=$(docker image ls ${TARGET} --format "{{.Size}}")
          echo "📊 Tamanho da imagem Docker: ${IMAGE_SIZE}"
          
          if [[ "${IMAGE_SIZE}" == *"kB"* || "${IMAGE_SIZE}" == *"KB"* ]]; then
            echo "⚠️ Aviso: A imagem parece ser muito pequena (${IMAGE_SIZE})!"
            if [[ "${IMAGE_SIZE}" == "1.1kB" || "${IMAGE_SIZE}" == "1.1KB" ]]; then
              echo "❌ A imagem tem exatamente 1.1KB, o que indica que não há arquivos de modelo!"
              exit 1
            fi
          fi
          
          # Enviar imagem para GHCR
          echo "📤 Enviando imagem para GHCR..."
          docker push ${TARGET}
      
      - name: Resultado
        run: |
          if [[ "${EXISTS}" == "true" ]]; then
            echo "ℹ️ Nenhuma ação: imagem já existia em GHCR."
          else
            echo "✅ Modelo publicado: ${TARGET}"
            echo ""
            echo "Para usar localmente:"
            echo "1. Crie um arquivo Modelfile:"
            echo "FROM ${TARGET}"
            echo ""
            echo "2. Execute: ollama create modelo-local -f ./Modelfile"
            echo "3. Use: ollama run modelo-local"
          fi
