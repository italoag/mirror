name: Sync Ollama Model to GHCR
on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Nome do modelo (ex: deepseek-r1)'
        required: true
      model_tag:
        description: 'Tag do modelo (ex: 7b, 671b)'
        required: true
      force_resync:
        description: 'Forçar ressincronização mesmo se já existir'
        required: false
        type: boolean
        default: false
jobs:
  sync-model:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Set Variables
        id: vars
        run: |
          MODEL_NAME="${{ github.event.inputs.model_name }}"
          MODEL_TAG="${{ github.event.inputs.model_tag }}"
          FORCE="${{ github.event.inputs.force_resync }}"
          MODEL_FULL="${MODEL_NAME}:${MODEL_TAG}"
          TARGET="ghcr.io/${{ github.repository_owner }}/${MODEL_NAME}:${MODEL_TAG}"
          echo "MODEL_NAME=${MODEL_NAME}" >> $GITHUB_ENV
          echo "MODEL_TAG=${MODEL_TAG}" >> $GITHUB_ENV
          echo "MODEL_FULL=${MODEL_FULL}" >> $GITHUB_ENV
          echo "FORCE=${FORCE}" >> $GITHUB_ENV
          echo "TARGET=${TARGET}" >> $GITHUB_ENV
      
      - name: Login no GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}
      
      - name: Check if Image Exists
        id: check
        continue-on-error: true
        run: |
          if [[ "${FORCE}" != "true" ]]; then
            if docker manifest inspect "${TARGET}" >/dev/null 2>&1; then
              echo "EXISTS=true" >> $GITHUB_ENV
              echo "✅ Já existe: ${TARGET}"
            else
              echo "EXISTS=false" >> $GITHUB_ENV
            fi
          else
            echo "EXISTS=false" >> $GITHUB_ENV
            echo "🔄 Forçando ressincronização"
          fi
      
      - name: Configurar Ambiente para Ollama
        if: env.EXISTS == 'false'
        run: |
          # Instalar Ollama localmente
          curl -fsSL https://ollama.com/install.sh | sh
          
          # Criar diretórios de trabalho
          mkdir -p /tmp/ollama-data
          mkdir -p /tmp/model-files
          
          # Inicie o serviço Ollama
          echo "🚀 Iniciando o serviço Ollama..."
          ollama serve &
          sleep 5
          
          # Baixar o modelo
          echo "📥 Baixando modelo ${MODEL_FULL}..."
          ollama pull ${MODEL_FULL}
          
          # Encontrar diretório onde o Ollama armazena os modelos
          OLLAMA_DIR="$HOME/.ollama"
          echo "🔍 Verificando diretório do Ollama: ${OLLAMA_DIR}"
          
          # Verificar estrutura de diretórios
          echo "📂 Estrutura de diretórios:"
          find ${OLLAMA_DIR} -type d | sort
          
          # Verificar arquivos grandes
          echo "📄 Arquivos grandes (>10MB):"
          find ${OLLAMA_DIR} -type f -size +10M | sort
          
          # Copiar arquivos relevantes
          echo "📦 Copiando arquivos..."
          
          # Arquivos binários e de configuração
          for EXT in "bin" "gguf" "json"; do
            find ${OLLAMA_DIR} -name "*.${EXT}" -exec cp -v {} /tmp/model-files/ \;
          done
          
          # Copiar arquivos grandes (modelo principal)
          find ${OLLAMA_DIR} -type f -size +10M -exec cp -v {} /tmp/model-files/ \;
          
          # Verificar conteúdo
          echo "📋 Arquivos copiados:"
          ls -lah /tmp/model-files/
          
          # Se não encontrar arquivos, tentar diretório de blobs
          if [ ! "$(ls -A /tmp/model-files/)" ]; then
            echo "⚠️ Nenhum arquivo encontrado. Tentando copiar diretórios de blobs..."
            BLOBS_DIR=$(find ${OLLAMA_DIR} -path "*/blobs" -type d | head -n 1)
            
            if [ -n "$BLOBS_DIR" ]; then
              echo "Copiando blobs de: ${BLOBS_DIR}"
              cp -rv ${BLOBS_DIR}/* /tmp/model-files/
            fi
            
            # Verificar novamente
            echo "📋 Arquivos após tentativa de blobs:"
            ls -lah /tmp/model-files/
          fi
          
          # Segunda alternativa - explorar /usr/local
          if [ ! "$(ls -A /tmp/model-files/)" ]; then
            echo "⚠️ Tentando localizar em /usr/local/share/ollama..."
            if [ -d "/usr/local/share/ollama" ]; then
              find /usr/local/share/ollama -type f -size +1M -exec cp -v {} /tmp/model-files/ \;
            fi
            
            echo "📋 Arquivos após tentativa alternativa:"
            ls -lah /tmp/model-files/
          fi
          
          # Verificar tamanho total
          TOTAL_SIZE=$(du -sh /tmp/model-files/ | cut -f1)
          echo "📊 Tamanho total dos arquivos: ${TOTAL_SIZE}"
          
          if [ ! "$(ls -A /tmp/model-files/)" ]; then
            echo "❌ Não foi possível encontrar os arquivos do modelo!"
            
            # Exploração mais profunda
            echo "🔎 Realizando busca em todo o sistema por arquivos de modelo..."
            sudo find / -name "*.gguf" -o -name "*.bin" -size +100M 2>/dev/null | grep -v "proc\|sys" | head -n 10
            
            exit 1
          fi
          
          # Criar Dockerfile
          echo "📝 Criando Dockerfile..."
          cat > /tmp/model-files/Dockerfile << EOF
          FROM scratch
          COPY . /
          LABEL org.opencontainers.image.title="${MODEL_FULL}"
          LABEL org.opencontainers.image.description="Ollama model ${MODEL_FULL} synced via GitHub Actions"
          CMD [""]
          EOF
          
          # Construir imagem
          echo "🏗️ Construindo imagem Docker..."
          cd /tmp/model-files/
          docker build -t ${TARGET} .
          
          # Verificar tamanho da imagem
          IMAGE_SIZE=$(docker image ls ${TARGET} --format "{{.Size}}")
          echo "📊 Tamanho da imagem: ${IMAGE_SIZE}"
          
          if [[ "${IMAGE_SIZE}" == *"kB"* || "${IMAGE_SIZE}" == *"KB"* ]]; then
            echo "⚠️ A imagem parece muito pequena (${IMAGE_SIZE})!"
            if [[ "${IMAGE_SIZE}" == "1.1kB" || "${IMAGE_SIZE}" == "1.1KB" ]]; then
              echo "❌ A imagem tem exatamente 1.1KB, o que indica que não há arquivos de modelo!"
              exit 1
            fi
          fi
          
          # Enviar imagem para GHCR
          echo "📤 Enviando imagem para GHCR..."
          docker push ${TARGET}
      
      - name: Resultado
        run: |
          if [[ "${EXISTS}" == "true" ]]; then
            echo "ℹ️ Nenhuma ação: imagem já existia em GHCR."
          else
            echo "✅ Modelo publicado: ${TARGET}"
            echo ""
            echo "Para usar localmente:"
            echo "1. Crie um arquivo Modelfile com o conteúdo:"
            echo "FROM ${TARGET}"
            echo ""
            echo "2. Execute: ollama create modelo-local -f ./Modelfile"
            echo "3. Use: ollama run modelo-local"
          fi
