name: Sync Ollama Model to GHCR
on:
  workflow_dispatch:
    inputs:
      model_name:
        description: 'Nome do modelo (ex: deepseek-r1)'
        required: true
      model_tag:
        description: 'Tag do modelo (ex: 7b, 671b)'
        required: true
      force_resync:
        description: 'Forçar ressincronização mesmo se já existir'
        required: false
        type: boolean
        default: false
jobs:
  sync-model:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Set Variables
        id: vars
        run: |
          MODEL_NAME="${{ github.event.inputs.model_name }}"
          MODEL_TAG="${{ github.event.inputs.model_tag }}"
          FORCE="${{ github.event.inputs.force_resync }}"
          MODEL_FULL="${MODEL_NAME}:${MODEL_TAG}"
          TARGET="ghcr.io/${{ github.repository_owner }}/public/${MODEL_NAME}:${MODEL_TAG}"
          echo "MODEL_NAME=${MODEL_NAME}" >> $GITHUB_ENV
          echo "MODEL_TAG=${MODEL_TAG}" >> $GITHUB_ENV
          echo "MODEL_FULL=${MODEL_FULL}" >> $GITHUB_ENV
          echo "FORCE=${FORCE}" >> $GITHUB_ENV
          echo "TARGET=${TARGET}" >> $GITHUB_ENV
      
      - name: Login no GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.repository_owner }}
          password: ${{ secrets.GHCR_PAT }}
      
      - name: Check if Image Exists
        id: check
        continue-on-error: true
        run: |
          if [[ "${FORCE}" != "true" ]]; then
            if docker manifest inspect "${TARGET}" >/dev/null 2>&1; then
              echo "EXISTS=true" >> $GITHUB_ENV
              echo "✅ Já existe: ${TARGET}"
            else
              echo "EXISTS=false" >> $GITHUB_ENV
            fi
          else
            echo "EXISTS=false" >> $GITHUB_ENV
            echo "🔄 Forçando ressincronização"
          fi
      
      - name: Sincronizar Modelo
        if: env.EXISTS == 'false'
        run: |
          echo "🐳 Executando container Ollama"
          
          # Criar diretório para dados do Ollama
          mkdir -p /tmp/ollama-data
          
          # Iniciar container Ollama em background
          docker run -d --name ollama -v /tmp/ollama-data:/root/.ollama -p 11434:11434 ollama/ollama
          
          # Aguardar inicialização do serviço
          sleep 10
          
          echo "📥 Pull do modelo ${MODEL_FULL}"
          docker exec ollama ollama pull ${MODEL_FULL}
          
          # Encontrar onde o modelo está armazenado dentro do container
          MODEL_DIR=$(docker exec ollama find /root/.ollama/models -type d -name "${MODEL_NAME}*${MODEL_TAG}*" | head -n 1)
          
          if [ -z "$MODEL_DIR" ]; then
            echo "❌ Não foi possível encontrar o diretório do modelo dentro do container"
            docker exec ollama ls -la /root/.ollama/models
            exit 1
          fi
          
          echo "📦 Modelo encontrado em: ${MODEL_DIR}"
          
          # Criar diretório temporário para o modelo no host
          mkdir -p /tmp/model
          
          # Copiar os arquivos do modelo do container para o host
          docker cp ollama:${MODEL_DIR}/. /tmp/model/
          
          # Criar Dockerfile
          cat > /tmp/model/Dockerfile << EOF
          FROM scratch
          COPY . /
          LABEL org.opencontainers.image.description="Ollama model ${MODEL_FULL}"
          CMD [""]
          EOF
          
          # Construir e enviar imagem
          cd /tmp/model
          docker build -t ${TARGET} .
          docker push ${TARGET}
          
          # Limpar
          docker stop ollama
          docker rm ollama
      
      - name: Resultado
        run: |
          if [[ "${EXISTS}" == "true" ]]; then
            echo "ℹ️ Nenhuma ação: imagem já existia em GHCR."
          else
            echo "✅ Modelo publicado: ${TARGET}"
            echo "   Para usar: ollama pull ${TARGET}"
          fi
